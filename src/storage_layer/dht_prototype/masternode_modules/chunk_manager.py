import os
import logging
from collections import deque

from .settings import NetWorkSettings
from .chunk_storage import ChunkStorage
from .masternode import MasterNodeManager
from .helpers import get_digest, get_hexdigest, get_intdigest, hex_to_int, int_to_hex


class Chunk:
    def __init__(self, chunkid, exists=False, verified=False, is_ours=False):
        if type(chunkid) != int:
            raise ValueError("chunkid is not int!")

        self.chunkid = chunkid
        self.exists = exists
        self.verified = verified
        self.is_ours = is_ours

    def __str__(self):
        return "chunkid: %s, exists: %s, verified: %s, is_ours: %s" % (self.chunkid, self.exists,
                                                                       self.verified, self.is_ours)


class ChunkManager:
    def __init__(self, name, nodeid, masternode_settings, chunks, masternode_list):
        # node's name in logfiles
        self.__name = name

        # initialize logger
        # IMPORTANT: we must ALWAYS use self.__logger.* for logging and not logging.*,
        # since we need instance-level logging
        self.__logger = None
        self.__initlogging()

        # our node id
        self.__nodeid = hex_to_int(nodeid)

        # settings
        self.__masternode_settings = masternode_settings

        # the actual storage layer
        storagedir = os.path.join(self.__masternode_settings.BASEDIR, "chunkdata")
        self.__storage = ChunkStorage(storagedir, mode=0o0700)

        # databases we keep
        self.__file_db = {}
        self.__alias_db = {}

        # helper lookup table for alias generation and other nodes
        self.__alias_digests = []

        # table of every chunk we know of
        self.__chunk_table = set()

        # masternode manager
        self.__mn_manager = MasterNodeManager(masternode_list)

        # todolist
        # TODO: use the todolist and defer all blocking tasks to it
        self.__todolist = deque()

        # run other initializations
        self.__initialize(chunks)

    def __str__(self):
        return "%s" % self.__nodeid

    def __initialize(self, chunks):
        self.__logger.debug("Initializing")

        # sanity check
        self.__mn_manager.get(self.__nodeid)

        # initializations
        self.__init_chunk_table(chunks)
        self.__init_alias_digests()
        self.__discover_files_in_local_storage()
        self.__recalculate_ownership_of_all_chunks()
        self.__purge_orphaned_db_entries()
        self.__purge_orphaned_files()
        self.__dump_internal_stats()

    def __initlogging(self):
        self.__logger = logging.getLogger(self.__name)
        self.__logger.setLevel(logging.DEBUG)

        formatter = logging.Formatter(' %(asctime)s - ' + self.__name + ' - %(levelname)s - %(message)s')
        consolehandler = logging.StreamHandler()
        consolehandler.setFormatter(formatter)
        self.__logger.addHandler(consolehandler)

    def __init_chunk_table(self, chunks):
        for chunk_str in chunks:
            chunk = int(chunk_str, 16)
            self.__chunk_table.add(chunk)
        self.__logger.debug("Added %s chunks to chunk table" % len(self.__chunk_table))

    def __init_alias_digests(self):
        for i in range(NetWorkSettings.REPLICATION_FACTOR):
            digest = get_digest(i.to_bytes(1, byteorder='big') + NetWorkSettings.ALIAS_SEED)
            digest_int = int.from_bytes(digest, byteorder='big')
            self.__logger.debug("Alias digest %s -> %s" % (i, digest_int))
            self.__alias_digests.append(digest_int)

    def __discover_files_in_local_storage(self):
        self.__logger.debug("Indexing local files")

        # reads the filesystem and fills our DB of chunks we have
        for chunkid in self.__storage.index():
            # verify the chunk
            if not self.__storage.verify(chunkid):
                self.__logger.warning("Verify failed for chunkid %s, deleting" % chunkid)
                self.__storage.delete(chunkid)
                continue

            # update our database
            if self.__file_db.get(chunkid) is None:
                chunk = Chunk(chunkid=chunkid)
                self.__file_db[chunkid] = chunk
            else:
                chunk = self.__file_db[chunkid]

            chunk.exists = True
            chunk.verified = True
            chunk.is_ours = False  # we don't know yet whether this is our chunk

        self.__logger.debug("Discovered %s files in local storage" % len(self.__file_db))

    def __recalculate_ownership_of_all_chunks(self):
        for chunkid in self.__chunk_table:
            self.__calculate_chunk_ownership(chunkid)

    def __calculate_chunk_ownership(self, chunkid):
        owned = False

        # maintain the alias table
        alias_updates = []
        for alias_digest in self.__alias_digests:
            alt_key = alias_digest ^ chunkid

            alias_owned = self.__we_own_this_alt_key(alt_key)
            alias_updates.append((alt_key, alias_owned))

            if alias_owned:
                # if we own the alias we own the chunk
                owned = True

        # maintain alias db
        for alt_key, alt_key_owned in alias_updates:
            if alt_key_owned:
                # this alias points to us
                # self.__logger.debug("Alt key %s is now OWNED (chunkid: %s)" % (alt_key, chunkid))
                self.__alias_db[alt_key] = chunkid
            else:
                # this alias not longer points to us
                # self.__logger.debug("Alt key %s is now DISOWNED (chunkid: %s)" % (alt_key, chunkid))
                if self.__alias_db.get(alt_key) is not None:
                    del self.__alias_db[alt_key]

        # if even a single alias says we own this chunk, we do
        if owned:
            # maintain file db
            chunk = self.__get_or_create_chunk(chunkid)
            if not chunk.is_ours:
                # self.__logger.debug("Chunk %s is now OWNED" % chunkid)
                chunk.is_ours = True

            # if we don't have it or it's not verified for some reason, fetch it
            if not chunk.exists or not chunk.verified:
                # TODO: fetch chunk
                pass
        else:
            # maintain file db
            chunk = self.__get_or_create_chunk(chunkid, create=False)
            if chunk is not None:
                if chunk.is_ours:
                    # self.__logger.debug("Chunk %s is now DISOWNED" % chunkid)
                    chunk.is_ours = False

    def __we_own_this_alt_key(self, alt_key):
        my_distance = alt_key ^ self.__nodeid

        # check if we are the closest to this chunk
        store = True
        for othernodeid in self.__mn_manager.get_other_nodes(self.__nodeid):
            if alt_key ^ othernodeid < my_distance:
                store = False
                break

        return store

    def __purge_orphaned_files(self):
        self.__logger.info("Purging orphaned files")
        for chunkid, chunk in self.__file_db.items():
            if chunk.exists:
                if not chunk.is_ours or not chunk.verified:
                    self.__storage.delete(chunkid)

    def __purge_orphaned_db_entries(self):
        self.__logger.info("Purging orphaned DB entries")
        to_delete = []
        for chunkid, chunk in self.__file_db.items():
            if not chunk.exists and not chunk.is_ours:
                to_delete.append(chunkid)

        for chunkid in to_delete:
            del self.__file_db[chunkid]

    def __get_or_create_chunk(self, chunkid, create=True):
        if self.__file_db.get(chunkid) is None:
            if not create:
                return None
            else:
                self.__file_db[chunkid] = Chunk(chunkid=chunkid)

        chunk = self.__file_db[chunkid]
        return chunk

    def update_mn_list(self, masternode_list):
        added, removed = self.__mn_manager.update_maternode_list(masternode_list)
        if len(added) + len(removed) > 0:
            if self.__nodeid in removed:
                self.__logger.warning("I am removed from the MN list, aborting %s" % self.__nodeid)
                # return

            self.__logger.info("MN list has changed -> added: %s, removed: %s" % (added, removed))
            self.__dump_internal_stats("DB STAT Before")
            self.__recalculate_ownership_of_all_chunks()
            self.__purge_orphaned_db_entries()
            self.__purge_orphaned_files()
            self.__dump_internal_stats("DB STAT After")

    def new_chunks_added_to_blockchain(self, chunks):
        self.__dump_internal_stats("DB STAT Before")
        for chunk_str in chunks:
            chunkid = int(chunk_str, 16)
            self.__chunk_table.add(chunkid)
            self.__calculate_chunk_ownership(chunkid)
        self.__dump_internal_stats("DB STAT After")

    def get_chunk_ownership(self, chunk_str):
        chunkid = int(chunk_str, 16)
        if self.__file_db.get(chunkid) is not None:
            return self.__file_db[chunkid].is_ours
        else:
            return False

    # DEBUG FUNCTIONS
    def __dump_internal_stats(self, msg=""):
        self.__logger.debug("%s -> Aliases: %s, file_db: %s, chunk_table: %s" % (msg, len(self.__alias_db),
                                                                    len(self.__file_db),
                                                                    len(self.__chunk_table)))

    def __dump_chunks(self):
        for k, v in self.__alias_db.items():
            self.__logger.debug("ALIAS %s: %s" % (k, v))
        for k, v in self.__file_db.items():
            self.__logger.debug("FILE %s: %s" % (k, v))
    # END
