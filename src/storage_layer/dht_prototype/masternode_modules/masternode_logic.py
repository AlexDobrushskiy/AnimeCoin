import asyncio
import random
import logging

import zmq
import zmq.asyncio

from .settings import NetWorkSettings
from .chunk_manager import ChunkManager
from .masternode_communication import NodeManager
from .helpers import get_hexdigest, hex_to_int, int_to_hex
from .rpc import pack_and_sign, verify_and_unpack


class RPCFailed(Exception):
    pass


class MasterNodeLogic:
    def __init__(self, name, nodeid, basedir, privkey, pubkey, masternode_list, chunks):
        self.__name = name
        self.__nodeid = hex_to_int(nodeid)
        self.__basedir = basedir
        self.__privkey = privkey
        self.__pubkey = pubkey

        self.__todolist = asyncio.Queue()

        # initialize logging
        self.__initlogging()

        # masternode manager
        self.__mn_manager = NodeManager(masternode_list)

        # chunk manager
        self.__chunkmanager = ChunkManager(self.__logger, self.__nodeid,
                                           basedir,
                                           chunks,
                                           self.__mn_manager, self.__todolist)

        # message queue
        mn = self.__mn_manager.get(self.__nodeid)

        # functions exposed from chunkmanager
        self.load_full_chunks = self.__chunkmanager.load_full_chunks

        # our RPC socket
        self.__zmq = zmq.asyncio.Context().socket(zmq.ROUTER)
        self.__zmq.setsockopt(zmq.IDENTITY, bytes(str(self.__nodeid), "utf-8"))
        self.__zmq.bind("tcp://%s:%s" % (mn.ip, mn.port))

        # define our RPCs
        self.__RPCs = {
            "SPOTCHECK_REQ": ["SPOTCHECK_RESP", self.__receive_rpc_spotcheck],
            "FETCHCHUNK_REQ": ["FETCHCHUNK_RESP", self.__receive_rpc_fetchchunk],
        }

    def __initlogging(self):
        self.__logger = logging.getLogger(self.__name)
        self.__logger.setLevel(logging.DEBUG)

        formatter = logging.Formatter(' %(asctime)s - ' + self.__name + ' - %(levelname)s - %(message)s')
        consolehandler = logging.StreamHandler()
        consolehandler.setFormatter(formatter)
        self.__logger.addHandler(consolehandler)

    async def issue_random_tests_forever(self, waittime, number_of_chunks=1):
        while True:
            await asyncio.sleep(waittime)

            chunks = self.__chunkmanager.select_random_chunks_we_have(number_of_chunks)
            for chunkid in chunks:
                self.__logger.debug("Selected chunk %s for random check" % int_to_hex(chunkid))

                # get chunk
                data = self.__chunkmanager.get_chunk(chunkid, verify=True)

                # pick a random range
                assert len(data) > 1024
                start = random.randint(0, len(data)-1024)
                end = start + 1024

                # calculate digest
                digest = get_hexdigest(data[start:end])
                self.__logger.debug("Digest for range %s - %s is: %s" % (start, end, digest))

                # find owners for all the alt keys who are not us
                owners = self.__chunkmanager.find_owners_for_chunk(chunkid)
                if self.__nodeid in owners:
                    # we have already tested ourselves with verify()
                    owners.remove(self.__nodeid)

                # call RPC on all other MNs
                for owner in owners:
                    mn = self.__mn_manager.get(owner)

                    try:
                        response_digest = await self.__send_rpc_spotcheck(mn, chunkid, start, end)
                    except RPCFailed as exc:
                        self.__logger.info("SPOTCHECK RPC FAILED for node %s with exception %s" % (owner, exc))
                    else:
                        if response_digest != digest:
                            self.__logger.warning("SPOTCHECK FAILED for node %s (%s != %s)" % (owner, digest,
                                                                                               response_digest))
                        else:
                            self.__logger.debug("SPOTCHECK SUCCESS for node %s for chunk: %s" % (owner, digest))

                    # TODO: track successes/errors

    async def run_workers_forever(self):
        # TODO: speed this up (multiple coroutines perhaps?)
        while True:
            self.__logger.debug("TODOLIST: queue size: %s" % self.__todolist.qsize())
            todoitem = await self.__todolist.get()

            itemtype, itemdata = todoitem
            if itemtype == "MISSING_CHUNK":
                chunkid = itemdata
                self.__logger.debug("Fetching chunk %s" % chunkid)

                found = False
                for owner in self.__chunkmanager.find_owners_for_chunk(chunkid):
                    if owner == self.__nodeid:
                        continue
                    mn = self.__mn_manager.get(owner)

                    try:
                        chunk = await self.__send_rpc_fetchchunk(mn, chunkid)
                    except RPCFailed as exc:
                        self.__logger.info("FETCHCHUNK RPC FAILED for node %s with exception %s" % (owner, exc))
                        continue
                    else:
                        found = True
                        self.__logger.debug("Fetched chunk %s" % len(chunk))
                        break

                # nobody has this chunk
                if not found:
                    # TODO: fall back to reconstruct it from luby blocks
                    raise RuntimeError("Unable to fetch chunk %s!" % chunkid)

                # we have the chunk, store it!
                self.__chunkmanager.store_chunk(chunkid, chunk)

                # mark entry as done
                self.__todolist.task_done()
            else:
                raise ValueError("Invalid todo type: %s" % itemtype)

    def __return_rpc_packet(self, sender_id, msg):
        response_packet = pack_and_sign(self.__privkey,
                                        self.__pubkey,
                                        sender_id, msg)
        return response_packet

    def process_local_rpc(self, sender_id, rpcname, data):
        # get the appropriate rpc function or send back an error
        rpc = self.__RPCs.get(rpcname)
        if rpc is None:
            self.__logger.info("RPC %s is not implemented, ignoring packet!" % rpcname)

        # call the RPC function, catch all exceptions
        response_name, fn = self.__RPCs.get(rpcname)
        try:
            ret = fn(data)
        except Exception as exc:
            self.__logger.warning("Exception received while doing RPC: %s" % exc)
            msg = [response_name, "ERROR", "RPC ERRROR happened: %s" % exc]
        else:
            # generate response if everything went well
            msg = [response_name, "SUCCESS", ret]
        return self.__return_rpc_packet(sender_id, msg)

    async def __zmq_process(self, ident, msg):
        sender_id, received_msg = verify_and_unpack(msg, self.__pubkey)
        rpcname, data = received_msg

        reply_packet = self.process_local_rpc(sender_id, rpcname, data)

        await self.__zmq.send_multipart([ident, reply_packet])

    async def zmq_run_forever(self):
        while True:
            ident, msg = await self.__zmq.recv_multipart()  # waits for msg to be ready
            asyncio.ensure_future(self.__zmq_process(ident, msg))

    async def __send_rpc_to_mn(self, response_name, mn, msg):
        request_packet = self.__return_rpc_packet(mn.pubkey, msg)
        response_packet = await mn.send_rpc_and_wait_for_response(request_packet)

        sender_id, response_msg = verify_and_unpack(response_packet, self.__pubkey)

        rpcname, success, response_data = response_msg

        if rpcname != response_name:
            raise ValueError("Spotcheck response has rpc name: %s" % rpcname)

        if success != "SUCCESS":
            raise RPCFailed(response_msg)

        return response_data

    async def __send_rpc_spotcheck(self, mn, chunkid, start, end):
        self.__logger.debug("SPOTCHECK REQUEST to %s, chunkid: %s" % (int_to_hex(mn.nodeid), int_to_hex(chunkid)))

        # chunkid is bignum so we need to serialize it
        chunkid_str = int_to_hex(chunkid)
        request_msg = ["SPOTCHECK_REQ", {"chunkid": chunkid_str, "start": start, "end": end}]

        response_data = await self.__send_rpc_to_mn("SPOTCHECK_RESP", mn, request_msg)

        if set(response_data.keys()) != {"digest"}:
            raise ValueError("RPC parameters are wrong for SPOTCHECK_RESP: %s" % response_data.keys())

        if type(response_data["digest"]) != str:
            raise TypeError("digest is not str: %s" % type(response_data["digest"]))

        response_digest = response_data["digest"]

        self.__logger.debug("SPOTCHECK RESPONSE from %s, msg: %s" % (int_to_hex(mn.nodeid), response_digest))

        return response_digest

    async def __send_rpc_fetchchunk(self, mn, chunkid):
        self.__logger.debug("FETCHCHUNK REQUEST to %s, chunkid: %s" % (int_to_hex(mn.nodeid), int_to_hex(chunkid)))

        # chunkid is bignum so we need to serialize it
        chunkid_str = int_to_hex(chunkid)
        request_msg = ["FETCHCHUNK_REQ", {"chunkid": chunkid_str}]

        response_data = await self.__send_rpc_to_mn("FETCHCHUNK_RESP", mn, request_msg)

        if set(response_data.keys()) != {"chunk"}:
            raise ValueError("RPC parameters are wrong for FETCHCHUNK_RESP: %s" % response_data.keys())

        if type(response_data["chunk"]) != bytes:
            raise TypeError("chunk is not bytes: %s" % type(response_data["chunk"]))

        chunk = response_data["chunk"]

        # validate chunk
        digest = get_hexdigest(chunk)
        if digest != chunkid_str:
            raise ValueError("Got chunk data that does not match the digest!")

        return chunk

    def __receive_rpc_spotcheck(self, data):
        # NOTE: data is untrusted!
        if not isinstance(data, dict):
            raise TypeError("Data must be a dict!")

        if set(data.keys()) != {"chunkid", "start", "end"}:
            raise ValueError("Invalid arguments for spotcheck: %s" % (data.keys()))

        for k, v in data.items():
            if k in ["start", "end"]:
                if not isinstance(v, int):
                    raise TypeError("Invalid type for key %s in spotcheck" % k)
            else:
                if not isinstance(v, str):
                    raise TypeError("Invalid type for key %s in spotcheck" % k)

        chunkid = hex_to_int(data["chunkid"])
        start = data["start"]
        end = data["end"]

        # check if start and end are within parameters
        if start < 0:
            raise ValueError("start is < 0")
        if start >= end:
            raise ValueError("start >= end")
        if start > NetWorkSettings.CHUNKSIZE or end > NetWorkSettings.CHUNKSIZE:
            raise ValueError("start > CHUNKSIZE or end > CHUNKSIZE")

        # we don't actually need the full chunk here, but we get it anyway as we are running verify() on it
        chunk = self.__chunkmanager.return_chunk_data_if_valid_and_owned_and_we_have_it(chunkid)

        # generate digest
        data = chunk[start:end]
        digest = get_hexdigest(data)

        return {"digest": digest}

    def __receive_rpc_fetchchunk(self, data):
        # NOTE: data is untrusted!
        if not isinstance(data, dict):
            raise TypeError("Data must be a dict!")

        if set(data.keys()) != {"chunkid"}:
            raise ValueError("Invalid arguments for spotcheck: %s" % (data.keys()))

        if not isinstance(data["chunkid"], str):
            raise TypeError("Invalid type for key chunkid in spotcheck")

        chunkid = hex_to_int(data["chunkid"])

        # TODO: error handling
        chunk = self.__chunkmanager.return_chunk_data_if_valid_and_owned_and_we_have_it(chunkid)

        return {"chunk": chunk}
