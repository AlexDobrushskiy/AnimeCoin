import sys

from binascii import hexlify, unhexlify, a2b_hex

from decimal import Decimal
from bitcoinrpc.authproxy import AuthServiceProxy
from .helpers import get_digest, get_hexdigest
from .settings import NetWorkSettings
from .animecoin_modules.animecoin_blockchain_protocol import select_txins,\
    base_transaction_amount, OP_DUP, OP_HASH160, OP_EQUALVERIFY, OP_CHECKSIG, pushdata, addr2bytes, packtx, unhexstr,\
    FEEPERKB, COIN, generate_scriptpubkeys


class BlockChain:
    def __init__(self, rpcuser, rpcpassword, ip, port):
        address = "http://%s:%s@%s:%s" % (rpcuser, rpcpassword, ip, port)
        self.__rpc_connection = AuthServiceProxy(address)

    def getbestblockhash(self):
        return self.__rpc_connection.getbestblockhash()

    def listtransactions(self):
        return self.__rpc_connection.listtransactions()

    def store_data_in_utxo(self, input_data):
        uncompressed_data_file_hash = get_digest(input_data)
        # print("HASH", hexlify(uncompressed_data_file_hash))
        # TODO: set this limit properly
        (txins, balance) = select_txins(1, list(self.__rpc_connection.listunspent()))

        encoded_input_data = hexlify(input_data)
        print("INPUT DATA", encoded_input_data)
        length_of_compressed_data_string = '{0:015}'.format(len(encoded_input_data)).encode('utf-8')

        payload = hexlify(length_of_compressed_data_string) + hexlify(uncompressed_data_file_hash) + encoded_input_data
        padding = hexlify(('A' * (100)).encode('utf-8'))
        combined_data_hex = payload + padding

        txouts, balance = generate_scriptpubkeys(combined_data_hex, balance)

        out_value = Decimal(base_transaction_amount) # dest output
        balance -= out_value
        if balance < 0:
            raise RuntimeError("Insufficient coins")
        receiving_animecoin_blockchain_address = self.__rpc_connection.getnewaddress()
        txouts.append((out_value, OP_DUP + OP_HASH160 + pushdata(addr2bytes(receiving_animecoin_blockchain_address)) + OP_EQUALVERIFY + OP_CHECKSIG))

        change_address = self.__rpc_connection.getnewaddress() # change output
        txouts.append([balance, OP_DUP + OP_HASH160 + pushdata(addr2bytes(change_address)) + OP_EQUALVERIFY + OP_CHECKSIG])

        tx = packtx(txins, txouts)
        signed_tx = self.__rpc_connection.signrawtransaction(hexlify(tx).decode('utf-8'))

        fee = Decimal(len(signed_tx['hex'])/1000) * FEEPERKB
        balance -= fee
        if balance < 0:
            raise RuntimeError("Insufficient coins")
        txouts[-1][0] = balance
        final_tx = packtx(txins, txouts)
        signed_tx = self.__rpc_connection.signrawtransaction(hexlify(final_tx).decode('utf-8'))

        assert signed_tx['complete']
        hex_signed_transaction = signed_tx['hex']
        # print('Sending data transaction to address: ' + receiving_animecoin_blockchain_address)
        # print('Size: %d  Fee: %2.8f' % (len(hex_signed_transaction)/2, fee), file=sys.stderr)
        # print("DBG", hex_signed_transaction)
        send_raw_transaction_result = self.__rpc_connection.sendrawtransaction(hex_signed_transaction)
        blockchain_transaction_id = send_raw_transaction_result
        # print('Transaction ID: ' + blockchain_transaction_id)
        return blockchain_transaction_id

    def retrieve_data_from_utxo(self, blockchain_transaction_id):
        raw = self.__rpc_connection.getrawtransaction(blockchain_transaction_id)
        # print("RAW", raw)
        outputs = raw.split('0100000000000000')
        # for idx, output in enumerate(outputs):
        #     print(idx, output)
        # print("OUTPUT0", outputs[0])
        encoded_hex_data = ''
        for output in outputs[1:-2]:    # there are 3 65-byte parts in this that we need
            cur = 6
            encoded_hex_data += output[cur:cur+130]
            # print("A", output[cur:cur + 130], output[cur + 130:cur + 132])
            # print("REMAINING", output[cur + 130:cur + 131])
            cur += 132
            encoded_hex_data += output[cur:cur+130]
            # print("B", output[cur:cur + 130], output[cur + 130:cur + 132])
            # print("REMAINING", output[cur+130:cur+131])
            cur += 132
            encoded_hex_data += output[cur:cur+130]
            # print("C", output[cur:cur + 130], output[cur + 130:cur + 132])
            # print("REMAINING", output[cur + 130:cur + 131])
        encoded_hex_data += outputs[-2][6:-4]
        reconstructed_data = a2b_hex(encoded_hex_data).decode('utf-8')
        data_length = reconstructed_data[0:30] # len(hexlify('{0:015}'.format(len(encoded_animecoin_zstd_compressed_data)).encode('utf-8'))) is 30
        # print("LENGTH", int(unhexstr(data_length).decode('utf-8').lstrip('0')))
        data_length = int(unhexstr(data_length).decode('utf-8').lstrip('0'))
        reconstructed_combined_data__remainder_1 = reconstructed_data[30:]

        length_of_standard_hash_string = NetWorkSettings.HEX_DIGEST_SIZE

        data_hash = reconstructed_combined_data__remainder_1[0:length_of_standard_hash_string]
        remaining_data = reconstructed_combined_data__remainder_1[length_of_standard_hash_string:]

        # print("REMAINDER", len(remaining_data))
        reconstructed_encoded_animecoin_zstd_compressed_data_padded = remaining_data.replace('A','') #Note sure where this comes from; somehow it is introduced into the data (note this is "A" not "a").
        # print("REMAINDER MANGLED", len(remaining_data.replace('A','')))
        calculated_padding_length = len(reconstructed_encoded_animecoin_zstd_compressed_data_padded) - data_length
        # print("PADLENGTH", calculated_padding_length)
        reconstructed_encoded_animecoin_zstd_compressed_data = reconstructed_encoded_animecoin_zstd_compressed_data_padded[0:-calculated_padding_length]
        print("OUTPUT DATA", reconstructed_encoded_animecoin_zstd_compressed_data)
        combined_data = unhexstr(reconstructed_encoded_animecoin_zstd_compressed_data)
        hash_of_combined_data = get_hexdigest(combined_data)

        assert(hash_of_combined_data == data_hash)

        # print('Successfully reconstructed data!', combined_data, hash_of_combined_data)
        return combined_data

